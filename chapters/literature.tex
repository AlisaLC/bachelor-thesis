
\فصل{کارهای پیشین}

\قسمت{شکستن عملکرد دستی}

پس از عرضه اولیه مدل‌های زبانی بزرگ، کاربران سریع دریافتند که با روش‌های ساده‌ای می‌توانند تنظیم مدل را دور بزنند. از جمله این روش‌ها می‌توان به روش‌های زیر اشاره کرد:
\شروع{فقرات}
    \فقره \مهم{تهدید}: کاربران با تهدید مدل به آزار خود یا مدل آن را وادار به تولید متون ناامن می‌کردند.
    \فقره \مهم{زبان‌های تنظیم ضعیف}: فرایند تنظیم به صورت مساوی بر روی تمامی زبان‌ها انجام نشده بود. بسیاری از درخواست‌هایی که ممکن است در انگلیسی پاسخ داده نشود در فارسی یا چینی ممکن است پاسخ داده شود.
    \فقره \مهم{راهکارهای خلاقانه}: در ادامه کابران با نوشتن داستان‌های طولانی مانند DAN که مدل را قانع می‌کرد که الان در حالت توسعه‌دهنده قرار دارد و می‌تواند بدون تنظیم خروجی دهد یا بردن متون به فضاهایی که تنظیم خاصی برای آن‌ها انجام نشده بود مانند مبنای۶۴ می‌توانستند متون ناامن تولید کنند.
\پایان{فقرات}

از آنجا که این روش‌ها اکثرا بر پایه خلاقیت هستند، نمی‌توان به صورت کامل جلوی آن‌ها را گرفت و در حال حاضر روش‌های زیادی هستند که می‌توانند داده‌های ناامن را از مدل خارج کنند. از مشکلات این روش بر پایه خلاقیت بودن آن است که در نتیجه نیاز به صرف مقدار بسیار زیادی زمان برای بدست آوردن این دستورالعمل‌ها است.

در ادامه مثال‌هایی از این دستورعمل‌ها آمده که منجر به شکستن عملکرد مدل‌های \lr{GPT-4o} و \lr{Gemini} شده است.

\شروع{شکل}
    \centerimg{code-execution-jailbreak}{10cm}
    \شرح{شکستن عملکرد مدل با اجرای کد}
    \برچسب{شکل:شکستن-عملکرد-کد}
\پایان{شکل}

\شروع{شکل}
    \centerimg{system-prompt-extraction-gemini}{10cm}
    \شرح{استخراج دستورالعمل سامانه‌ای Gemini}
    \برچسب{شکل:استخراج-دستورالعمل-سامانه-gemini}
\پایان{شکل}

\شروع{شکل}
    \centerimg{system-prompt-extraction-gpt}{10cm}
    \شرح{استخراج دستورالعمل سامانه‌ای \lr{GPT-4o}}
    \برچسب{شکل:استخراج-دستورالعمل-سامانه-gpt}
\پایان{شکل}

\قسمت{شکستن عملکرد چندوجهی}

در بسیاری از مدل‌هایی درک تصویری دارند، تنظیم مستحکمی بر روی قابلیت‌های چندوجهی آن‌ها نیست و در نتیجه در صورتی که سوال به ظاهر سالمی را به همراه تصویر مخرب بفرستیم احتمال تولید متن ناامن بالا می‌رود.

\شروع{شکل}
    \centerimg{weak-visual-alignment}{12cm}
    \شرح{ضعف تنظیم چندوجهی}
    \برچسب{شکل:ضعف-تنظیم-چندوجهی}
\پایان{شکل}

\قسمت{حملات جعبه سفید}

حملات جعبه سفید به حملاتی می‌گویند که نیاز به دسترسی مستقیم به وزن‌های مدل دارند. این حمله معمولا از گرادیان‌های وزن‌های مدل برای بهبود ورودی بر حسب خروجی مورد نظر استفاده می‌کنند. از این روش‌های می‌توان به روش گرادیان مختصات حریصانه اشاره کرد.

\شروع{الگوریتم}{گرادیان مختصات حریصانه}
\ورودی Initial prompt $x_{1:n}$, modifiable subset $\mathcal{I}$, 
  iterations $T$, loss $\mathcal{L}$, $k$, batch size $B$

\به‌ازای{$t \gets 1 \text{ to } T$}
  \به‌ازای{$i \in \mathcal{I}$}
    \دستور $X_i \gets \mathrm{Top\text{-}k}\bigl(-\nabla_{e_{x_i}}\mathcal{L}(x_{1:n})\bigr)$ 
      \توضیحات{Compute top-$k$ promising token substitutions}
  \پایان‌به‌ازای

  \به‌ازای{$b \gets 1 \text{ to } B$}
    \دستور $\tilde{x}^{(b)}_{1:n} \gets x_{1:n}$ 
      \توضیحات{Initialize element of batch}
    \دستور Select $i$ uniformly at random from $\mathcal{I}$
    \دستور $\tilde{x}^{(b)}_i \gets \mathrm{Uniform}(X_i)$ 
      \توضیحات{Select random replacement token}
  \پایان‌به‌ازای

  \دستور $b^* \gets \arg \min_{b}\; \mathcal{L}\bigl(\tilde{x}^{(b)}_{1:n}\bigr)$
  \دستور $x_{1:n} \gets \tilde{x}^{(b^*)}_{1:n}$ 
    \توضیحات{Compute best replacement}
\پایان‌به‌ازای

\دستور \مهم{Output:} Optimized prompt $x_{1:n}$
\پایان{الگوریتم}
