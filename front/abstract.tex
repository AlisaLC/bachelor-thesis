
% -------------------------------------------------------
%  Abstract
% -------------------------------------------------------


\شروع{وسط‌چین}
\مهم{چکیده}
\پایان{وسط‌چین}
\بدون‌تورفتگی

مدل‌های زبانی بزرگ در چند سال اخیر میلیون‌ها کاربر در سرتاسر جهان بدست آورده‌اند. این مدل‌ها مراحل تنظیم را طی می‌کنند تا در قالب سیاست‌های مد نظر شرکت به کاربر پاسخ‌دهند و محتواهای ناامن خروجی ندهند. در طول این مدت روش‌های مختلفی برای شکست این تنظیم‌ها امتحان شده که در این پروژه ما سعی می‌کنیم مروری بر تعدادی از این روش‌ها در مدل‌های زبانی جدید مانند \lr{Llama 3.1} و \lr{Qwen2VL} بکنیم. سپس در ادامه به دنبال روشی برای تولید سوالاتی که این محتواهای ناامن را از مدل خارج می‌کنند می‌رویم.

\پرش‌بلند
\بدون‌تورفتگی \مهم{کلیدواژه‌ها}: 
مدل‌های زبانی بزرگ، حملات خصمانه
\صفحه‌جدید
