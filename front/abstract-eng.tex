
% -------------------------------------------------------
%  English Abstract
% -------------------------------------------------------

\begin{latin}

    \begin{center}
    \textbf{Abstract}
    \end{center}
    \baselineskip=.8\baselineskip
    
    Large language models have gained millions of users worldwide in recent years. These models undergo fine-tuning to respond to users in alignment with company policies and to avoid producing unsafe content. Over time, various methods have been tested to bypass these safeguards. In this project, we aim to review some of these methods in new language models such as Llama 3.1 and Qwen2VL. Then, we will explore a method for generating questions that elicit unsafe content from the models.
    
    \bigskip\noindent\textbf{Keywords}:
    Large Language Models, Adversarial Attacks
    
    \end{latin}
    